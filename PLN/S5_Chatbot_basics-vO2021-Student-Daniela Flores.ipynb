{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1. CREACIÓN E IMPORTACIÓN DEL CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Importar texto para obtener una sola cadena con todo el texto: 'Aquí va todo el texto. Aunque sean muchas oraciones separadas con comas o puntos. Se le llama texto plano o \"raw text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El curso de Minería de Textos tiene 8 créditos que se traduce a un tiempo de dedicación de 8 horas totales repartidas en 3 horas BCD y 5 horas TIE.\\nBCD significa o es igual a Bajo Conducción Docente. \\nTIE significa o es igual a Tiempo Independiente del Estudiante.\\nLa CLAVE DE ASIGNATURA es MSC2499A.\\nEste curso pertenece al programa académico de posgrado de la Maestría en Sistemas Computacionales, en el departamento de Electrónica, Sistemas e Informática.\\nEl horario del curso es cada Lunes de 7pm a 10pm.\\nEl curso pertenece a la COORDINACIÓN DOCENTE de Aprendizaje Automático.\\nEl curso se imparte en el idioma Español.\\nLa profesora que imparte el curso durante este periodo es la Doctora Mildreth Isadora Alcaraz Mejía, Profesora Titular.\\nEl correo de la profesora es mildreth@iteso.mx.\\nLa página web personal de la profesora es https://www.iteso.mx/web/general/detalle?group_id=3083477 .\\nEl PROPÓSITO GENERAL del curso es desarrollar habilidades y conocer herramientas para convertir información no estructurada a información estructurada usando técnicas de procesamiento del lenguaje natural y de la inteligencia artificial con fines de visualización, clasificación o análisis de los contenidos. \\nLos PROPÓSITOS ESPECÍFICOS del curso son: Conocer los conceptos básicos de la minería de textos para el tratamiento de texto no estructurado; Aprender a manejar herramientas básicas de procesamiento del lenguaje natural y de la inteligencia artificial para la visualización, clasificación y análisis de textos; Implementar aplicaciones prácticas para la vida real utilizando los conceptos de la minería de textos y las herramientas de procesamiento del lenguaje natural y de la inteligencia artificial.\\nLos requerimientos para las clases en línea son Canvas como LMS (Learning Management System), MS Teams, Cámara web, Micrófono, Buena conexión a Internet; y los requerimientos para el desarrollo de los temas del curso son principalmente: Jupyter Notebook, Python, Nltk.\\nPara el acceso a las plataformas del curso, como son Canvas y MS Teams, se usa la cuenta y contraseña del ITESO.\\nPara mayor información del curso puede dirigirse al correo de contacto: mildreth@iteso.mx o al teléfono de contacto: 3334343669 extensión 3975.\\nEl nombre de la profesora del curso de Minería de Textos es Mildreth Alcaraz.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2310"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_PATH = 'C:\\\\Users\\\\DanielaFloresRuiz\\\\Documents\\\\DSM\\\\MineríaT\\\\Clase 15 - Chatbot Texto\\\\Corpus_TextMiningCourse.txt'\n",
    "\n",
    "with open(FILE_PATH, 'r') as f:\n",
    "    doc_raw = f.read()\n",
    "\n",
    "doc_raw # imprime el texto de entrada\n",
    "len(doc_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_raw = 'El curso de Minería de Textos tiene 8 créditos que se traduce a un tiempo de dedicación de 8 horas totales repartidas en 3 horas BCD y 5 horas TIE.\\nBCD significa o es igual a Bajo Conducción Docente. \\nTIE significa o es igual a Tiempo Independiente del Estudiante.\\nLa CLAVE DE ASIGNATURA es MSC2499A.\\nEste curso pertenece al programa académico de posgrado de la Maestría en Sistemas Computacionales, en el departamento de Electrónica, Sistemas e Informática.\\nEl horario del curso es cada Lunes de 7pm a 10pm.\\nEl curso pertenece a la COORDINACIÓN DOCENTE de Aprendizaje Automático.\\nEl curso se imparte en el idioma Español.\\nLa profesora que imparte el curso durante este periodo es la Doctora Mildreth Isadora Alcaraz Mejía, Profesora Titular.\\nEl correo de la profesora es mildreth@iteso.mx.\\nLa página web personal de la profesora es https://www.iteso.mx/web/general/detalle?group_id=3083477 .\\nEl PROPÓSITO GENERAL del curso es desarrollar habilidades y conocer herramientas para convertir información no estructurada a información estructurada usando técnicas de procesamiento del lenguaje natural y de la inteligencia artificial con fines de visualización, clasificación o análisis de los contenidos. \\nLos PROPÓSITOS ESPECÍFICOS del curso son: Conocer los conceptos básicos de la minería de textos para el tratamiento de texto no estructurado; Aprender a manejar herramientas básicas de procesamiento del lenguaje natural y de la inteligencia artificial para la visualización, clasificación y análisis de textos; Implementar aplicaciones prácticas para la vida real utilizando los conceptos de la minería de textos y las herramientas de procesamiento del lenguaje natural y de la inteligencia artificial.\\nLos requerimientos para las clases en línea son Canvas como LMS (Learning Management System), MS Teams, Cámara web, Micrófono, Buena conexión a Internet; y los requerimientos para el desarrollo de los temas del curso son principalmente: Jupyter Notebook, Python, Nltk.\\nPara el acceso a las plataformas del curso, como son Canvas y MS Teams, se usa la cuenta y contraseña del ITESO.\\nPara mayor información del curso puede dirigirse al correo de contacto: mildreth@iteso.mx o al teléfono de contacto: 3334343669 extensión 3975.\\nEl nombre de la profesora del curso de Minería de Textos es Mildreth Alcaraz.\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2. PREPROCESAMIENTO DEL CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Crear una función para remover los signos de puntuación. La función recibe una oración y retorna la oración sin signos de puntuación. Si el corpus que se está trabajando contiene enlaces o correos-e, hay que considerarlo aquí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "x = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "def remove_punct_sent(tokenized_sent):\n",
    "    new_sent = []\n",
    "    for token in tokenized_sent.split(' '):\n",
    "        if '@' not in token and 'http' not in token:\n",
    "            new_token = re.sub(x, '', token)\n",
    "        else:\n",
    "            new_token = token\n",
    "        if not new_token == '':\n",
    "            new_sent.append(new_token)\n",
    "    return new_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Crear una función para normalizar por oración:\n",
    "1. Remover la puntuación de la oración (llamando a la función creada en el paso anterior)\n",
    "2. Convertir a minúsculars y aplicar \"stem\" o \"lemmatize\" para cada token de la oración de entrada, sólo si la palabra no es una palabra de parada (stopword)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "stops=stopwords.words('spanish')\n",
    "\n",
    "def sent_norm(sent_):\n",
    "    sent = remove_punct_sent(sent_)\n",
    "    norm_sent = [stemmer.stem(word.lower()) \n",
    "                 for word in sent if word not in stops]\n",
    "    return norm_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Separar el texto plano de entrada en oraciones, es decir, \"tokenize by sentence\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['El curso de Minería de Textos tiene 8 créditos que se traduce a un tiempo de dedicación de 8 horas totales repartidas en 3 horas BCD y 5 horas TIE.',\n",
       " 'BCD significa o es igual a Bajo Conducción Docente.',\n",
       " 'TIE significa o es igual a Tiempo Independiente del Estudiante.',\n",
       " 'La CLAVE DE ASIGNATURA es MSC2499A.',\n",
       " 'Este curso pertenece al programa académico de posgrado de la Maestría en Sistemas Computacionales, en el departamento de Electrónica, Sistemas e Informática.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "doc_sent = sent_tokenize(doc_raw)\n",
    "len(doc_sent)\n",
    "doc_sent[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3. Vectorizar el documento de entrada o corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Obtener el vector TF-IDF utilizando como tokenizador la función para normalizar por oración creada en el paso 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dfloresr/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/dfloresr/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17, 130)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<5x130 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 41 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.20547265, 0.        , 0.        , 0.20547265,\n",
       "        0.        , 0.41094531, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17941506,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20547265, 0.        ,\n",
       "        0.08517952, 0.20547265, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.61641796, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.1609269 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20547265, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1609269 , 0.17941506, 0.17941506,\n",
       "        0.        , 0.20547265, 0.20547265, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.44500348, 0.        , 0.3885691 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.44500348,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3885691 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3885691 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3885691 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.44500348, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3885691 , 0.        , 0.        , 0.44500348,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3885691 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3885691 , 0.3885691 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.57735027, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.27805359, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.27805359, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.11526824, 0.        , 0.27805359, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.27805359, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.27805359, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.27805359, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.24279143, 0.        , 0.27805359, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.27805359, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.55610717, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=sent_norm)\n",
    "tfidf_vect_fit = tfidf_vect.fit(doc_sent)\n",
    "tfidf_vect_doc = tfidf_vect_fit.transform(doc_sent)\n",
    "tfidf_tokens_doc = tfidf_vect.get_feature_names()\n",
    "\n",
    "tfidf_vect_doc.shape\n",
    "type(tfidf_vect_doc)\n",
    "tfidf_vect_doc[0:5][:]\n",
    "tfidf_vect_doc.toarray()[0:5][:]\n",
    "len(tfidf_tokens_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 130)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t2\n",
      "  (0, 19)\t1\n",
      "  (0, 38)\t1\n",
      "  (0, 40)\t1\n",
      "  (0, 41)\t1\n",
      "  (0, 57)\t3\n",
      "  (0, 86)\t1\n",
      "  (0, 108)\t1\n",
      "  (0, 117)\t1\n",
      "  (0, 118)\t1\n",
      "  (0, 119)\t1\n",
      "  (0, 121)\t1\n",
      "  (0, 122)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 29)\t1\n",
      "  (1, 45)\t1\n",
      "  (1, 61)\t1\n",
      "  (1, 110)\t1\n",
      "  (2, 51)\t1\n",
      "  (2, 61)\t1\n",
      "  (2, 64)\t1\n",
      "  (2, 110)\t1\n",
      "  (2, 118)\t1\n",
      "  (2, 119)\t1\n",
      "  (3, 15)\t1\n",
      "  (3, 26)\t1\n",
      "  (3, 88)\t1\n",
      "  (4, 7)\t1\n",
      "  (4, 27)\t1\n",
      "  (4, 40)\t1\n",
      "  (4, 42)\t1\n",
      "  (4, 47)\t1\n",
      "  (4, 66)\t1\n",
      "  (4, 77)\t1\n",
      "  (4, 96)\t1\n",
      "  (4, 98)\t1\n",
      "  (4, 103)\t1\n",
      "  (4, 111)\t2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(tokenizer=sent_norm)\n",
    "count_vect_fit = count_vect.fit(doc_sent)\n",
    "count_vect_doc = count_vect_fit.transform(doc_sent)\n",
    "count_tokens_doc = count_vect.get_feature_names()\n",
    "\n",
    "count_vect_doc.shape\n",
    "type(count_vect_doc)\n",
    "print(count_vect_doc[0:5][:])\n",
    "count_vect_doc.toarray()[0:5][:]\n",
    "len(count_tokens_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4. Determinar coincidencias manualmente: Función de SALUDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "welcome = {\n",
    "    'hola': '¡Hola!',\n",
    "    'buenos días': '¡Buenos días!',\n",
    "    'oiga': 'Dígame, ¿En qué puedo ayudarle?',\n",
    "    'buen día': '¡Buen día!',\n",
    "    'buenas tardes' : '¡Buenas tardes!',\n",
    "    'buenas noches' : '¡Buenas noches!',\n",
    "    'buena tarde' : '¡Buenas tardes!',\n",
    "    'buena noche' : '¡Buenas noches!',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5. Función para calcular la vectorización de la pregunta del usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Obtener el vector para la pregunta del usuario:\n",
    "Función vectorization_q que recibe la pregunta del usuario:\n",
    "1. Normalizar la pregunta del usuario\n",
    "2. Crear un vector de zeros con numpy de tamaño 1xn, n = el número de tokens o características (features) obtenidas en la vectorización del corpus.\n",
    "3. Para cada token obtenido del paso 1, si el token existe dentro del conjunto de tokens o features obtenidos en la vectorización, asignar en la posición correspondiente a ese token en la lista de features del documento vectorizado el valor de acuerdo al tipo de TF-IDF elegido.\n",
    "4. Convertir el vector obtenido en el paso 3, a una matriz csr, la cual correspondera al tfidf de la pregunta del usuario.\n",
    "\n",
    "##### NOTA: Si los valores que se asignan para cada token incluido en la consulta o pregunta del usuario son equivalentes al tipo de TD-IDF elegido para la vectorización del corpus, entonces simplemente se pasa la consulta por la función de transform, de la instancia de tfidf creado y entrenado para el corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El curso se imparte en el idioma Español.\n",
      "El curso se imparte en el idioma Español.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
    "\n",
    "msg = 'Idioma del curso'\n",
    "\n",
    "def tfidf_vectorization_q(q_):\n",
    "    q = tfidf_vect_fit.transform(q_)\n",
    "    return q\n",
    "\n",
    "print(doc_sent[np.argmax([cosine_similarity(sent_, tfidf_vectorization_q(sent_tokenize(msg))) for sent_ in tfidf_vect_doc])])\n",
    "\n",
    "def count_vect_vectorization_q(q_):\n",
    "    q = count_vect_fit.transform(q_)\n",
    "    return q\n",
    "\n",
    "print(doc_sent[np.argmax([cosine_similarity(sent_, count_vect_vectorization_q(sent_tokenize(msg))) for sent_ in count_vect_doc])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Paso 6. Conversación: recepción de saludo, pregunta del usuario y generación de respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Iniciar conversación - chat, informar  salir, y recibir posible saludo.\n",
    "2. Saludar al usuario y dar bienvenida.\n",
    "3. Recibir pregunta del usuario.\n",
    "4. Calcular la similitud entre los vectores TF-IDF de la pregunta del usuario y los TF-IDF de los párrafos del corpus: usando la librería de cosine_similarity de sklearn.metrics.pairwise.\n",
    "5. Ordenar el vector de similitudes obtenido usando argsort. argsort es una matrix de tamaño 1xm, donde m = el número de oraciones que componen el corpus, es decir, la longitud del documento separado por oraciones.\n",
    "6. Obtener el de mayor similtud y retornarlo como respuesta al usuario.\n",
    "7. Invitar al usuario a realizar otra pregunta e ir a 3.\n",
    "8. Despedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03261966]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.04414219]]\n",
      "[[0.06980752]]\n",
      "[[0.07325321]]\n",
      "[[0.63195264]]\n",
      "[[0.0515202]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.0335274]]\n",
      "[[0.02174238]]\n",
      "[[0.03176096]]\n",
      "[[0.05458343]]\n",
      "[[0.04289598]]\n",
      "[[0.07540499]]\n"
     ]
    }
   ],
   "source": [
    "for sent_ in tfidf_vect_doc:\n",
    "    sim = cosine_similarity(sent_, tfidf_vectorization_q(sent_tokenize(msg)))\n",
    "    print(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo de la dinámica del CHATBOT\n",
    "\n",
    "Chatbot: Bienvenido al chat sobre información del curso de Minería de Textos.\n",
    "Chatbot: Si deseas salir teclea la palabra \"Bye\"\n",
    "Tú: Hola\n",
    "Chatbot: ¡Hola!\n",
    "Chatbot: ¿En qué puedo ayudarte?\n",
    "Tú: objetivos particulares del curso\n",
    "Chatbot: El curso se imparte en el idioma Español.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: objetivos específicos\n",
    "Chatbot: Los PROPÓSITOS ESPECÍFICOS del curso son: Conocer los conceptos básicos de la minería de textos para el tratamiento de texto no estructurado; Aprender a manejar herramientas básicas de procesamiento del lenguaje natural y de la inteligencia artificial para la visualización, clasificación y análisis de textos; Implementar aplicaciones prácticas para la vida real utilizando los conceptos de la minería de textos y las herramientas de procesamiento del lenguaje natural y de la inteligencia artificial.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: objetivo general\n",
    "Chatbot: El PROPÓSITO GENERAL del curso es desarrollar habilidades y conocer herramientas para convertir información no estructurada a información estructurada usando técnicas de procesamiento del lenguaje natural y de la inteligencia artificial con fines de visualización, clasificación o análisis de los contenidos.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: créditos\n",
    "Chatbot: El curso de Minería de Textos tiene 8 créditos que se traduce a un tiempo de dedicación de 8 horas totales repartidas en 3 horas BCD y 5 horas TIE.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: horario\n",
    "Chatbot: El horario del curso es cada Lunes de 7pm a 10pm.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: bced\n",
    "Chatbot: Disculpa, no he encontrado una respuesta a tu consulta.\n",
    "Chatbot: Para más información, escribe a: help@ctm.iteso.mx\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: bcd\n",
    "Chatbot: BCD significa o es igual a Bajo Conducción Docente.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: horas bcd\n",
    "Chatbot: El curso de Minería de Textos tiene 8 créditos que se traduce a un tiempo de dedicación de 8 horas totales repartidas en 3 horas BCD y 5 horas TIE.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: bye\n",
    "Chatbot: Un gusto atenderte. ¡Hasta pronto!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostSimilar(text):\n",
    "    similarities = [cosine_similarity(sent_, tfidf_vectorization_q(sent_tokenize(msg))) for sent_ in tfidf_vect_doc]\n",
    "    #print(max(similarities))\n",
    "    if(max(similarities) > 0.20):\n",
    "        return doc_sent[np.argmax(similarities)]\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Bienvenido al chat sobre información del curso de Minería de Textos.\n",
      "Chatbot: Si deseas salir teclea la palabra 'Bye'\n",
      "Chatbot: ¿En qué puedo ayudarte?\n",
      "horario\n",
      "Tu:, horario\n",
      "El horario del curso es cada Lunes de 7pm a 10pm.\n",
      "Chatbot: ¿En qué puedo ayudarte?\n",
      "objetivos\n",
      "Tu:, objetivos\n",
      "Chatbot: Disculpa, no he encontrado una respuesta a tu consulta.\n",
      "Chatbot: Para más información, escribe a: help@ctm.iteso.mx\n",
      "Chatbot: ¿En qué puedo ayudarte?\n",
      "propósito\n",
      "Tu:, propósito\n",
      "Chatbot: Disculpa, no he encontrado una respuesta a tu consulta.\n",
      "Chatbot: Para más información, escribe a: help@ctm.iteso.mx\n",
      "Chatbot: ¿En qué puedo ayudarte?\n",
      "nombre de la maestra\n",
      "Tu:, nombre de la maestra\n",
      "El nombre de la profesora del curso de Minería de Textos es Mildreth Alcaraz.\n",
      "Chatbot: ¿En qué puedo ayudarte?\n",
      "perritos \n",
      "Tu:, perritos \n",
      "Chatbot: Disculpa, no he encontrado una respuesta a tu consulta.\n",
      "Chatbot: Para más información, escribe a: help@ctm.iteso.mx\n",
      "Chatbot: ¿En qué puedo ayudarte?\n",
      "bye\n",
      "Tu:, bye\n",
      "-1\n",
      "Chatboot: Un gusto atenderte. ¡Hasta pronto!\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot: Bienvenido al chat sobre información del curso de Minería de Textos.\")\n",
    "print(\"Chatbot: Si deseas salir teclea la palabra 'Bye'\")\n",
    "msg = ' '\n",
    "\n",
    "while msg.lower() != \"bye\":\n",
    "    print(\"Chatbot: ¿En qué puedo ayudarte?\")\n",
    "    msg = input()\n",
    "    print(f\"Tu:, {msg}\")\n",
    "    similarity = getMostSimilar(msg)\n",
    "    if(-1 == similarity) and msg.lower() != 'bye':\n",
    "        print('Chatbot: Disculpa, no he encontrado una respuesta a tu consulta.')\n",
    "        print('Chatbot: Para más información, escribe a: help@ctm.iteso.mx')\n",
    "    else:\n",
    "        print(similarity)\n",
    "    #print(doc_sent[np.argmax([cosine_similarity(sent_, vectorization_q(sent_tokenize(msg))) for sent_ in tfidf_vect_doc])])\n",
    "\n",
    "print('Chatboot: Un gusto atenderte. ¡Hasta pronto!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "452f24582ce7179faa6a4a4bc582d55e8544c4d0800fd49aec0cee67d546f7c9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
